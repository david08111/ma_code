model:
#  model_architecture_file_path: "/work/scratch/dziuba/repos/ma_code/cfg/model_example.yaml"
  model_architecture:
#    model_architecture_origin: torchvision
#    model_architecture_name: deeplabv3_resnet50
    model_architecture_origin: segmentation_models_pytorch
    model_architecture_name: unet_inceptionresnetv2
#    model_architecture_origin: mmseg
#    model_architecture_name: ocrnet-r101-d8-cityscapes
    pretrained: True
    embedding_dims: 50
  channels: 3
  output_creation:  # first list element will be used to create the panoptic output prediction
#    - multi_sphere_association:
#        cat_id_radius_order_map_list: [ 7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33 ] #describes the mapping of the semantic class to the order of hyperspheres - from small hypersphere to big or regarding to index
#        radius_diff_dist: 0.1        # difference to next class association radius
#        radius_start_val: 0.1           # start radius value
#        radius_association_margin: 0.05  # max deviation from radius to still associate to closest radius
#        instance_clustering_method:
#          identity: {} # no args specified
#    - sphere_coords:
#        mean_origin: False
#
    - nearest_class_mean_association:
        instance_clustering_method:
          identity: { } # no args specified
#          cuml_hdbscan:
#            min_samples: 4
#     - multi_sphere_association_flexible:
#        radius: 1
#        radius_association_margin: 0.5  # max deviation from radius to still associate to closest radius
#        instance_clustering_method:
#          identity: { } # no args specified
    - radius:
        mean_origin: False


optimizer:
  adam:
    lr: 0.001
    eps: 0.00000001
    weight_decay: 0
    warmup:
      start_lr: 0.00001
      end_lr: 0.001
      num_steps: 2500

scheduler:
  reduce_on_plateau:
    eps: 0.00000001
    factor: 0.1
    patience: 10
    threshold: 0.0001
    cooldown: 20

training:
  save_path: "/work/scratch/dziuba/ma_code_runs/trainings/debug28"
#  gpu_ids: [0]
  save_freq: 10
  metrics_calc_freq: 10
  num_epochs: 160
  use_cpp: False
  AMP: False
  compile: False
  best_eval_mode: "min"
  cuml_mem_alloc: 2000000000 # in MB?
  embedding_handler: # remove part if necessary for training
    storage_step_update_sample_size: 1     #per class base
    embedding_storage:
      memory_bank:
        num_embeddings: 500 # equally distributed to categories
    embedding_sampler:
      batch_sampler: {}

loss:
  train_loss:
    metric_learning_sem_segm:
      class_metric_loss:
        sphere_face_loss:
          num_classes: 19
          embedding_size: 50
#        arcface_loss:
#          num_classes: 19
#          embedding_size: 50
  val_loss:
    metric_learning_sem_segm:
      class_metric_loss:
        sphere_face_loss:
          num_classes: 19
          embedding_size: 50
#        arcface_loss:
#          num_classes: 19
#          embedding_size: 50
#  train_loss:
#    metric_learning:
#      class_metric_loss:
#        supconloss:
#          temperature: 0.1
#      inst_metric_loss:
#        supconloss:
#          temperature: 0.1
#  val_loss:
#    metric_learning:
#      class_metric_loss:
#        supconloss:
#          temperature: 0.1
#      inst_metric_loss:
#        supconloss:
#          temperature: 0.1
#  train_loss:
##    hierarchical_cluster_batch_contrast_panoptic:
#    hierarchical_cluster_mean_mov_avg_update_contrast_panoptic:
#      inter_cls_contrastive_loss:
#        mse_hinged_pos:
#          margin: 45
#          norm: 2
##          inner_loss:
##            mse:
##              reduction: None
#      intra_cls_contrastive_loss:
#        mse_hinged_neg:
#          margin: 15
#          norm: 2
##          inner_loss:
##            mse:
##              reduction: None
#      inter_inst_contrastive_loss:
#        mse_hinged_pos:
#          margin: 3
#          norm: 2
#      intra_inst_contrastive_loss:
#        mse_hinged_neg:
#          margin: 0.5
#          norm: 2
#      mov_avg_factor: 0.1
#      reg_loss_norm: 2
#      inter_cls_contrastive_loss_weight: 1
#      intra_cls_contrastive_loss_weight: 1
#      inter_inst_contrastive_loss_weight: 1
#      intra_inst_contrastive_loss_weight: 1
#      regularization_weight: 0.001
#  val_loss:
##    hierarchical_cluster_batch_contrast_panoptic:
#    hierarchical_cluster_mean_mov_avg_update_contrast_panoptic:
#      inter_cls_contrastive_loss:
#        mse_hinged_pos:
#          margin: 45
#          norm: 2
#      #          inner_loss:
#      #            mse:
#      #              reduction: None
#      intra_cls_contrastive_loss:
#        mse_hinged_neg:
#          margin: 15
#          norm: 2
#      #          inner_loss:
#      #            mse:
#      #              reduction: None
#      inter_inst_contrastive_loss:
#        mse_hinged_pos:
#          margin: 3
#          norm: 2
#      intra_inst_contrastive_loss:
#        mse_hinged_neg:
#          margin: 0.5
#          norm: 2
#      mov_avg_factor: 0.1
#      reg_loss_norm: 2
#      inter_cls_contrastive_loss_weight: 1
#      intra_cls_contrastive_loss_weight: 1
#      inter_inst_contrastive_loss_weight: 1
#      intra_inst_contrastive_loss_weight: 1
#      regularization_weight: 0.001
  metrics:
    - panoptic_quality:
        filter: None

#  metrics_file_path: "/work/scratch/dziuba/repos/ma_code/cfg/metrics_master.yaml"


data:
  datasets_file_path: "/work/scratch/dziuba/repos/ma_code/cfg/datasets_ref_debug_bigger.yaml"
  batch_size: 2
  num_workers: 2
  prefetch_factor: 4 # currently deprecated
  img_width: 256
  img_height: 256
  load_ram: False # loads data fully into the main memory
  load_orig_size: True
  augmentations_file_path: "/work/scratch/dziuba/repos/ma_code/cfg/augmentations_crop.yaml"

logging:
  name: "LOG"
  save_path: "/work/scratch/dziuba/ma_code_runs/logs/debug28"
  num_log_img: 5
  log_graph: False
  wandb_config:
    project: "MA"
    entity: "ma_dziuba"
  sampler:
    nthstep:
      step_size: [15, 15]


#  img_log_freq: 10 # set by metrics_calc_freq
#  num_log_img: 5


