## Dataset creation
### General process
To create the dataset (including the download of aerial images from OpenDataNRW, semantic segmentation label creation with OpenStreetMap based data and further processing) these steps have to be followed:

1. Download the dataset [description file](https://www.opengeodata.nrw.de/produkte/geobasis/lbi/dop/dop_jp2_f10_paketiert/dop_meta.zip) from opengeodata or [search here](https://www.opengeodata.nrw.de/produkte/geobasis/lbi/dop/dop_jp2_f10_paketiert/) if its not available anymore
2. Use `download_data -m METAFILE_PATH -s SAVE_PATH [-n AREA_TO_EXTRACT_IMGS_FROM ...] [-y YEAR_OF_IMG]` to automatically download images from OpenDataNRW. Images from different areas are only available for certain years (search [here](https://www.opengeodata.nrw.de/produkte/geobasis/) for valid years or use the default value)
3. As a next step a rough check of the data could be done with optional removal of bad or unwanted images. See "Inspecting/Selecting different stages of the Dataset" for further information on selection procedures. 
4. Use `convert_data -m FILEPATH_TO_METAFILE_FROM_OPENDATANRW -d FILEPATH_TO_DOWNLOADED_IMGS -s SAVEPATH [-v ] [-v_out VISUALIZATION_PATH] [-y YEAR]` to create segmantation masks for the downloaded images from OpenStreetMap data. To visualize the masks use the `-v` option and set a save path in the `v_out` option (strongly recommended - see next step).
5. As a next step the masks should be generally checked for accuracy (e.g. missalignment, overall width etc. - use the visualization from the previous step). See "Inspecting/Selecting different stages of the Dataset" for further information on selection procedures.
6. Use `create_dataset -imsz IMG -tr TRANSLATION_AMOUNT -sc SCALING_AMOUNT -d INPUT_PATH -s SAVE_PATH -ap AREA_PERCENTAGE -ep EMPTY_PERCENTAGE [-v] [-v_out VISUALIZATION_PATH]` to crop images for the final dataset with the given data augmentation parameters (data augmentation with cropping should result in images without information missing). `-imgsz` is the desired image size that will be used for cropping in the training process. `-tr` and `sc` specifiy the amount of translation and scaling used in later training. These informations will be used to calculate image sizes that can be transformed and cropped without missing information (usually padded with 0). The created dataset images can be much larger than expected.
7. [optional] Use `pre_process -d INPUT_DATA_PATH -s SAVE_PATH -lm LABEL_MARK [-v] [-v_out VISUALIZATION_PATH]` to add a little bit smoothing and run the GrabCut algorithm on image data with according masks to refine the final segmentation masks (results can be better or worse). `-lm` describes the name part in the data file names to tell images and labels apart (e.g. "mask" or "label").
8. As a next step the masks should be checked for more detailed errors/inaccuracies or unwanted parts. For the selection process "Inspecting/Selecting different stages of the Dataset" will be referred to.
9. Use `smooth_data -in INPUT_PATH -out OUTPUT_PATH -lm LABEL_MARK [-cp]` to apply a final little smoothing one the segmentation masks. `-cp` is set when the according image files should be copied to the OUTPUT_PATH specified in the options.
10. Finally use `split_data -in INPUT_PATH -train_out OUTPUT_PATH_TO_TRAIN_PART -val_out OUTPUT_PATH_TO_VALIDATION_PART -test_out OUTPUT_PATH_TO_TEST_PART -train_p TRAIN_PERCENTAGE -val_p VALIDATION_PERCENTAGE -test_p TEST_PERCENTAGE -lm LABEL_MARK` to split the whole dataset in training, validation and testset for evaluation purposes. `-train_p TRAIN_PERCENTAGE` and similar specify the percentage from the dataset that the trainingset etc. should have.

### Inspecting/Selecting different stages of the Dataset
To inspect a part or the whole result from different stages of the dataset creation [this tool](https://github.com/david08111/data_handling) can be used. After installation (similar as here) an input filepath can be specified so that data gets loaded into the tool. After that a part (or the whole) dataset will be gone through and selected with the use of the buttons or hotkeys (recommended). Within this process the current state can be saved and restored for later used (it also automatically saves after 50 images). Finally an output path has to be specified and the splitted data will be exported there. 

It is recommended to use the visualized data for inspection. Because the visualize data has the same name as the image and label data, `copy_img_from_mask -bd BASE_DATA_PATH -cd COPY_DATA_PATH -out OUTPUT_PATH -lm LABEL_MARK` can be used to copy the according real data to an output folder.

### Labeling data
To create segmentation masks from existing images [this tool](https://github.com/david08111/data_refinement_tool) can be used. After installation (similar as here) an input filepath can be specified so that data gets loaded into the tool. The masks can be created with a brush like tool that specifies background, possible background, foreground and possible foreground which will be used as rough input for the GrabCut algorithm to optimize on unary/binary values associated to a graph node. Each pixel in the image is associated to a graph node and GrabCut optimizes foreground/background seperation based on the earlier described values. Finally the mask or erase brush can be selected to correct small errors and the next image can be processed.
